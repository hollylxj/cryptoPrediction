{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# We devide y_labels into 8 bins:\n",
    "# 1st bin: delta  < -0.1; 2nd bin: -0.1 <= delta < -0.05; 3rd bin: -0.05 <= delta < -0.01;4th bin: -0.01 <= delta < 0;\n",
    "# 5th bin: 0 <= delta < 0.01; 6th bin: 0.01 <= delta < 0.05; 7th bin: 0.05 <= delta < 0.1; 8th bin: delta >= 0.1.\n",
    "\n",
    "import pickle\n",
    "import pandas\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Conv3D,Input, ZeroPadding3D, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, Convolution3D, MaxPooling2D, ZeroPadding2D,ZeroPadding3D \n",
    "from keras.layers.core import Reshape\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Merge \n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LambdaCallback\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "with open('BTC-USD-60.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "#:chunk = filter_df(df_chunk, event_type='Fill')\n",
    "# sort the data based on ascending-order of time\n",
    "data = data.sort_values(by=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the original valuse for the fulture delta calculation\n",
    "\n",
    "data_original = data\n",
    "data_original = data_original[data_original.close > 200]\n",
    "\n",
    "#print(data_original)\n",
    "close_price = np.array(data_original.close)\n",
    "#print(close_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop time\n",
    "data = data[data.close > 200]\n",
    "time = np.array(data.time)\n",
    "data = data.drop('time', 1)\n",
    "# data.low = np.log(data.low)\n",
    "# data.high = np.log(data.high)\n",
    "# data.open = np.log(data.open)\n",
    "# data.close = np.log(data.close)\n",
    "\n",
    "# print(data)\n",
    "# print(time)\n",
    "# print(data.close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalize\n",
    "# mean = data.mean(axis = 0)\n",
    "# std = data.std(axis = 0)\n",
    "# print(mean)\n",
    "# print(std)\n",
    "# data = (data - mean) / std\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_windows(window_data):\n",
    "    #normalized_data = []\n",
    "    #print(len(window_data))\n",
    "    window_data = (window_data / window_data[0]) - 1 \n",
    "#     window0 = window_data[0]\n",
    "#     for i in range(0,len(window_data)):\n",
    "#         #print(window0)\n",
    "#         window_data[i] = (float(window_data[i]) / float(window0)) - 1\n",
    "    return window_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch(delta,train_Y):\n",
    "    if delta < -0.1:\n",
    "        train_Y.append([1,0,0,0,0,0,0,0])\n",
    "\n",
    "    elif delta >= -0.1 and delta < -0.05:\n",
    "        train_Y.append([0,1,0,0,0,0,0,0])\n",
    "\n",
    "    elif delta >= -0.05 and delta < -0.01:\n",
    "        train_Y.append([0,0,1,0,0,0,0,0])\n",
    "\n",
    "    elif delta >= -0.01 and delta < 0:\n",
    "        train_Y.append([0,0,0,1,0,0,0,0])\n",
    "\n",
    "    elif delta >= 0 and delta < 0.01:\n",
    "        train_Y.append([0,0,0,0,1,0,0,0])\n",
    "\n",
    "    elif delta >= 0.01 and delta < 0.05:\n",
    "        train_Y.append([0,0,0,0,0,1,0,0])\n",
    "\n",
    "    elif delta >= 0.05 and delta < 0.1:\n",
    "        train_Y.append([0,0,0,0,0,0,1,0])\n",
    "\n",
    "    else:\n",
    "        train_Y.append([0,0,0,0,0,0,0,1])\n",
    "\n",
    "    return train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We devide y_labels into 8 bins:\n",
    "#1st bin: delta  < -0.1; 2nd bin: -0.1 <= delta < -0.05; 3rd bin: -0.05 <= delta < -0.01;4th bin: -0.01 <= delta < 0;\n",
    "#5th bin: 0 <= delta < 0.01; 6th bin: 0.01 <= delta < 0.05; 7th bin: 0.05 <= delta < 0.1; 8th bin: delta >= 0.1.\n",
    "\n",
    "# fc for delta: \n",
    "# train_X: the past 60 minute average close_price, dimension: (778302, 60)\n",
    "# train_Y: the delta bin for next minute. Dimension: (778302, 8)\n",
    "def fc_preprocess(data, close_price , time):\n",
    "    A = np.array(data.open)\n",
    "    B = np.array(data.close)\n",
    "    C = (A + B) / 2\n",
    "    \n",
    "    i = 0\n",
    "    train_X = []\n",
    "    train_Y = []\n",
    "    while i < len(data) - 60:\n",
    "        if time[i + 60] - time[i] == 3600: \n",
    "            \n",
    "            temp = C[i:i + 60]\n",
    "            #print(temp[60])\n",
    "            train_X.append(temp)\n",
    "            \n",
    "            delta = (close_price[i + 60] - close_price[i + 59]) / close_price[i + 59] * 100\n",
    "            \n",
    "            train_Y = switch(delta,train_Y)\n",
    "            \n",
    "        else:\n",
    "            i = i + 60\n",
    "    \n",
    "    return train_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = fc_preprocess(data, close_price, time)\n",
    "x_tmp = np.array(train_X)\n",
    "y_tmp = np.array(train_Y)\n",
    "print(x_tmp.shape)\n",
    "print(y_tmp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"train_X_normalized_fc_delta.csv\", train_X, delimiter = \",\")\n",
    "np.savetxt(\"train_Y_normalized_fc_delta.csv\", train_Y, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm for delta: \n",
    "# train_X: the past 60 minute information(low, high, open, close, volume), dimension: (778302, 60, 5)\n",
    "# train_Y: the delta bin for next minute. Dimension: (778302, 8)\n",
    "def lstm_preprocess(data, close_price, time):\n",
    "    window_length = 60\n",
    "    A = np.array(data.low)\n",
    "    B = np.array(data.high)\n",
    "    C = np.array(data.open)\n",
    "    D = np.array(data.close)\n",
    "    E = np.array(data.volume)\n",
    "    i = 0\n",
    "    train_X = []\n",
    "    train_Y = []\n",
    "    test_X = []\n",
    "    test_Y = []\n",
    "    de_norm_train = []\n",
    "    de_norm_test = []\n",
    "    error = 0\n",
    "    while i < len(C) - window_length:\n",
    "         \n",
    "        if time[i+window_length] - time[i] == window_length*60:\n",
    "            temp = []\n",
    "            copy_A = np.copy(A[i:i+window_length+1])\n",
    "            copy_B = np.copy(B[i:i+window_length+1])\n",
    "            copy_C = np.copy(C[i:i+window_length+1])\n",
    "            copy_D = np.copy(D[i:i+window_length+1])\n",
    "            copy_E = np.copy(E[i:i+window_length+1])\n",
    "            \n",
    "            \n",
    "            normalized_temp_A = normalize_windows(copy_A)\n",
    "            normalized_temp_B = normalize_windows(copy_A)\n",
    "            normalized_temp_C = normalize_windows(copy_A)\n",
    "            normalized_temp_D = normalize_windows(copy_A)\n",
    "            normalized_temp_E = normalize_windows(copy_A)\n",
    "            #print(len(normalized_temp_D[:-1]))\n",
    "            temp.append(normalized_temp_A[:-1])\n",
    "            temp.append(normalized_temp_B[:-1])\n",
    "            temp.append(normalized_temp_C[:-1])\n",
    "            temp.append(normalized_temp_D[:-1])\n",
    "            temp.append(normalized_temp_E[:-1])\n",
    "#         temp.append(year[i:i+60])\n",
    "#         temp.append(hour[i:i+60])\n",
    "\n",
    "            delta = (close_price[i + 60] - close_price[i + 59]) / close_price[i + 59] * 100\n",
    "            if i%5 == 0 :\n",
    "                test_X.append(temp)            \n",
    "                # like switch command in C, decide which bucket we should label.\n",
    "                test_Y = switch(delta,test_Y)\n",
    "                de_norm_test.append([copy_A[0], copy_B[0], copy_C[0], copy_D[0], copy_E[0]])\n",
    "            else:\n",
    "                train_X.append(temp)                       \n",
    "                # like switch command in C, decide which bucket we should label.\n",
    "                train_Y = switch(delta,train_Y)\n",
    "                de_norm_train.append([copy_A[0], copy_B[0], copy_C[0], copy_D[0], copy_E[0]])\n",
    "            i += 1\n",
    "        else:\n",
    "            i = i + 60\n",
    "\n",
    "    return train_X, train_Y, test_X, test_Y, de_norm_train, de_norm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y, de_norm_train, de_norm_test = lstm_preprocess(data, close_price, time)\n",
    "train_X = np.transpose(train_X, (0,2,1))\n",
    "test_X = np.transpose(test_X, (0,2,1))\n",
    "# for i in range(train_X.shape[2]):\n",
    "#     ss = StandardScaler()\n",
    "#     train_X[:,:,i] = ss.fit_transform(train_X[:,:,i])\n",
    "# for i in range(test_X.shape[2]):\n",
    "#     ss = StandardScaler()\n",
    "#     test_X[:,:,i] = ss.fit_transform(test_X[:,:,i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tmp = np.array(train_X)\n",
    "# y_tmp = np.array(train_Y)\n",
    "\n",
    "print(np.shape(train_X),np.shape(train_Y),np.shape(test_X),np.shape(test_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_X_normalized_lstm_delta.pkl\", train_X)\n",
    "np.save(\"train_Y_normalized_lstm_delta.pkl\", train_Y)\n",
    "np.save(\"test_X_normalized_lstm_delta.pkl\", test_X)\n",
    "np.save(\"test_Y_normalized_lstm_delta.pkl\", test_Y)\n",
    "np.save(\"de_norm_lstm_delta_train.pkl\", de_norm_train)\n",
    "np.save(\"de_norm_lstm_delta_test.pkl\", de_norm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline for delta: calculate the average delta in the past 60 minutes, and use this value for the prediction for next\n",
    "# minute\n",
    "# train_X: the past 60 minute close_price, dimension: (778302, 60)\n",
    "# train_Y: the delta bin for next minute. Dimension: (778302, 8)\n",
    "def baseline_preprocess(data, close_price , time):\n",
    "    \n",
    "    C = np.array(data.close)\n",
    "  \n",
    "    i = 0\n",
    "    train_X = []\n",
    "    train_Y = []\n",
    "    while i < len(data) - 60:\n",
    "        if time[i + 60] - time[i] == 3600: \n",
    "            \n",
    "            temp = close_price[i:i + 60]\n",
    "            #print(temp[60])\n",
    "            train_X.append(temp)\n",
    "            \n",
    "           # delta = (close_price[i + 59] - close_price[i]) / close_price[i] * 100 \n",
    "\n",
    "           # delta = delta / 60\n",
    "            delta = (close_price[i + 60] - close_price[i + 59]) / close_price[i + 59] * 100 \n",
    "            if delta < -0.1:\n",
    "                \n",
    "                train_Y.append([1,0,0,0,0,0,0,0])\n",
    "                i = i + 1\n",
    "            elif delta >= -0.1 and delta < -0.05:\n",
    "                \n",
    "                train_Y.append([0,1,0,0,0,0,0,0])\n",
    "                i = i + 1\n",
    "            elif delta >= -0.05 and delta < -0.01:\n",
    "                \n",
    "                train_Y.append([0,0,1,0,0,0,0,0])\n",
    "                i = i + 1\n",
    "            elif delta >= -0.01 and delta < 0:\n",
    "                train_Y.append([0,0,0,1,0,0,0,0])\n",
    "                i = i + 1\n",
    "            elif delta >= 0 and delta < 0.01:\n",
    "                train_Y.append([0,0,0,0,1,0,0,0])\n",
    "                i = i + 1   \n",
    "            elif delta >= 0.01 and delta < 0.05:\n",
    "                train_Y.append([0,0,0,0,0,1,0,0])\n",
    "                i = i + 1 \n",
    "            elif delta >= 0.05 and delta < 0.1:\n",
    "                train_Y.append([0,0,0,0,0,0,1,0])\n",
    "                i = i + 1 \n",
    "            else:\n",
    "                train_Y.append([0,0,0,0,0,0,0,1])\n",
    "                i = i + 1\n",
    "        else:\n",
    "            i = i + 60\n",
    "    \n",
    "    return train_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = baseline_preprocess(data, close_price, time)\n",
    "x_tmp = np.array(train_X)\n",
    "y_tmp = np.array(train_Y)\n",
    "print(x_tmp.shape)\n",
    "print(y_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"train_X_normalized_baseline_delta.csv\", train_X, delimiter = \",\")\n",
    "np.savetxt(\"train_Y_normalized_baseline_delta.csv\", train_Y, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of data in buckets\n",
    "train_X, train_Y = lstm_preprocess(data, close_price, time)\n",
    "train_X = np.transpose(train_X, (0,2,1))\n",
    "for i in range(train_X.shape[2]):\n",
    "    ss = StandardScaler()\n",
    "    train_X[:,:,i] = ss.fit_transform(train_X[:,:,i])\n",
    "x_tmp = np.array(train_X)\n",
    "y_tmp = np.array(train_Y)\n",
    "print(x_tmp.shape)\n",
    "print(y_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
